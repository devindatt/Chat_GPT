{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVPPBcyw7MvWiqQy1uuJWO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devindatt/Chat_GPT/blob/main/ChatGPT_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZL5V62ol0S0",
        "outputId": "4dab3813-3650-4c24-febe-e0b8c982d599"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 1.7 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.221213-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.7.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=92e5575c3a9afb25fd01e3f5d18b1b1c0c295e0609b1999ec7fcfdf7bc10b706\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "Successfully built openai\n",
            "Installing collected packages: types-pytz, pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.5.2.221213 types-pytz-2022.7.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **API KEYS** (get from https://beta.openai.com/account/api-keys)"
      ],
      "metadata": {
        "id": "CFih3Izxtipm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the API key for accessing the ChatGPT model\n",
        "import openai\n",
        "openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "uWNuauWOthZK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GENERATED CHATGPT CODE**"
      ],
      "metadata": {
        "id": "jSFVnN9Audew"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljqrdOg3lpw6",
        "outputId": "eb112923-4cb5-4c3e-a1d4-23e3ba6358ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your message: Explain to me how a Feature Store works with a machine Learning system?\n",
            "Response written to output.txt\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "\n",
        "\n",
        "# Get the message to input to the ChatGPT model\n",
        "message = input(\"Enter your message: \")\n",
        "\n",
        "# Use the ChatGPT model to generate a response to the message\n",
        "response = openai.Completion.create(engine=\"text-davinci-002\", prompt=message, max_tokens=1024)\n",
        "\n",
        "# Extract the generated response from the model's output\n",
        "generated_response = response['choices'][0]['text']\n",
        "\n",
        "# Write the response to a file\n",
        "with open(\"output.txt\", \"w\") as f:\n",
        "    f.write(generated_response)\n",
        "\n",
        "print(\"Response written to output.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gx2Iz5ycs7Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BEAUTIFY THE INTERFACE**"
      ],
      "metadata": {
        "id": "KtYarE-YwK1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uujzRW2s7bv",
        "outputId": "1ce077e9-d511-4cb8-929e-14d3fd9e9157"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 13.8 MB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 60.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 278 kB 50.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 106 kB 62.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 7.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 6.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.4 MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "iTuYEjcJs7e5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai.api_resources import engine\n",
        "def gpt_chat(prompt):\n",
        "  completions = openai.Completion.create(\n",
        "      engine='text-davinci-003',\n",
        "      prompt=prompt,\n",
        "      max_tokens=1024,\n",
        "      n=1,\n",
        "      temperature=0.5,    #sets how much 'randomness is in the output'\n",
        "  )\n",
        "\n",
        "  message = completions.choices[0].text\n",
        "  return message.strip()"
      ],
      "metadata": {
        "id": "3zRg0qVhtjT9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GRADIO CHAT INTERFACE CODE**"
      ],
      "metadata": {
        "id": "KRcbrWo2yYmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Chat interface function to repeat for every input and response\n",
        "def chatbot(input, history=[]):\n",
        "  output = gpt_chat(input)\n",
        "  history.append((input, output))\n",
        "  \n",
        "  return history, history"
      ],
      "metadata": {
        "id": "sH13gtIOxtDd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **START CHAT INTERFACE**"
      ],
      "metadata": {
        "id": "BvzqyMp1zPFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=chatbot,\n",
        "             inputs=['text', 'state'],\n",
        "             outputs=['chatbot', 'state']).launch(debug=True, share=True).launch()   #remove launch to stop debugging"
      ],
      "metadata": {
        "id": "JJESoJyPzOoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OPoE5jnbzzkr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}