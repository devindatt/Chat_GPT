{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devindatt/Chat_GPT/blob/main/ChatGPT_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZL5V62ol0S0",
        "outputId": "dcf1ab3f-2e01-4ec0-e5a5-f6ff1961c463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.8/dist-packages (0.25.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: pandas-stubs>=1.1.0.11 in /usr/local/lib/python3.8/dist-packages (from openai) (1.5.2.221213)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Requirement already satisfied: types-pytz>=2022.1.1 in /usr/local/lib/python3.8/dist-packages (from pandas-stubs>=1.1.0.11->openai) (2022.7.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFih3Izxtipm"
      },
      "source": [
        "# **API KEYS** (get from https://beta.openai.com/account/api-keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWNuauWOthZK"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Set the API key for accessing the ChatGPT model\n",
        "import openai\n",
        "openai.api_key = '[ENTER YOUR API KEY HERE]'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSFVnN9Audew"
      },
      "source": [
        "## **GENERATED CHATGPT CODE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljqrdOg3lpw6"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "\n",
        "\n",
        "# Get the message to input to the ChatGPT model\n",
        "message = input(\"Enter your message: \")\n",
        "\n",
        "# Use the ChatGPT model to generate a response to the message\n",
        "response = openai.Completion.create(engine=\"text-davinci-002\", prompt=message, max_tokens=1024)\n",
        "\n",
        "# Extract the generated response from the model's output\n",
        "generated_response = response['choices'][0]['text']\n",
        "\n",
        "# Write the response to a file\n",
        "with open(\"output.txt\", \"w\") as f:\n",
        "    f.write(generated_response)\n",
        "\n",
        "print(\"Response written to output.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gx2Iz5ycs7Y2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtYarE-YwK1O"
      },
      "source": [
        "## **BEAUTIFY THE INTERFACE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uujzRW2s7bv",
        "outputId": "1ce077e9-d511-4cb8-929e-14d3fd9e9157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 13.8 MB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 60.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 278 kB 50.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 106 kB 62.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 7.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 6.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.4 MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTuYEjcJs7e5"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zRg0qVhtjT9"
      },
      "outputs": [],
      "source": [
        "from openai.api_resources import engine\n",
        "def gpt_chat(prompt):\n",
        "  completions = openai.Completion.create(\n",
        "      engine='text-davinci-003',\n",
        "      prompt=prompt,\n",
        "      max_tokens=1024,\n",
        "      n=1,\n",
        "      temperature=0.5,    #sets how much 'randomness is in the output'\n",
        "  )\n",
        "\n",
        "  message = completions.choices[0].text\n",
        "  return message.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRcbrWo2yYmf"
      },
      "source": [
        "## **GRADIO CHAT INTERFACE CODE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sH13gtIOxtDd"
      },
      "outputs": [],
      "source": [
        "#Chat interface function to repeat for every input and response\n",
        "def chatbot(input, history=[]):\n",
        "  output = gpt_chat(input)\n",
        "  history.append((input, output))\n",
        "  \n",
        "  return history, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvzqyMp1zPFn"
      },
      "source": [
        "## **START CHAT INTERFACE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "JJESoJyPzOoH",
        "outputId": "5d29e26f-17b5-4c84-95af-4e7ac277e9a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://6c39159e-e6fa-4edf.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://6c39159e-e6fa-4edf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "gr.Interface(fn=chatbot,\n",
        "             inputs=['text', 'state'],\n",
        "             outputs=['chatbot', 'state']).launch(debug=True, share=True).launch()   #remove launch to stop debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPoE5jnbzzkr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfofilvx3dPTYKjUSMy1AB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}